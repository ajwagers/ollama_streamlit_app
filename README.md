# Ollama Streamlit App
I am building a streamlit interface for ollama and including RAG and Agent functionality.

v0 - This is a simple but functional webapp that allows you to chat with the LLM but has very little other features.

v0.1 - reworks some features and allows the user to select a model from their local Ollama instance.  Still skimpy on features.

v0.2 - Allows the user to set the client url and abstracted the API from the main script body.

v0.3 - Incorporated the LangChain libraries, added a Thinking... animation

v0.4 - Added the ability to save and reload chats.

v0.5 - Added a text input box for a RAG system as well as persistent memory across sessions.
